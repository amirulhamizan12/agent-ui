<div align="center">

<img width="1698" height="403" alt="Browser Use (2)" src="https://github.com/user-attachments/assets/1ab29f98-c0b9-48fe-bc30-b905a010cb9a" />

---

**Speech â†’ Web â†’ Done.**  
*Sets a new bar for Browserâ€‘Use agents: real control, real artifacts, real time â€” PRs, bookings, filings â€” not another chat demo.*

---

[![Browser-Use](https://img.shields.io/badge/Browser--Use-3.0-blue?style=flat-square&logo=github)](https://github.com/browser-use/browser-use)
[![Gemini AI](https://img.shields.io/badge/Gemini-AI-orange?style=flat-square&logo=google)](https://ai.google.dev/)
[![Next.js](https://img.shields.io/badge/Next.js-15-black?style=flat-square&logo=next.js)](https://nextjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue?style=flat-square&logo=typescript)](https://www.typescriptlang.org/)

</div>


## ðŸš€ Getting Started

### **Prerequisites**
- Node.js 18+ 
- npm or yarn
- Gemini AI API key
- Browser-Use API key

### **Installation**
```bash
# Clone the repository
git clone https://github.com/yourusername/realtime-studio-hackathon.git
cd realtime-studio-hackathon

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env.local
# Add your API keys to .env.local

# Start the development server
npm run dev
```

### **Environment Variables**
```env
NEXT_PUBLIC_GEMINI_API_KEY=your_gemini_api_key
NEXT_PUBLIC_BROWSER_USE_API_KEY=your_browser_use_api_key
```

## ðŸŽ¯ What judges will see in 2 minutes

1) You say a task out loud.
2) The agent opens a live browser view and performs the steps (clicks, forms, navigation, screenshots).
3) A tangible artifact appears: a PR link, an issue comment, or a polished report you can share on X.

## ðŸ“Š Benchmarks that matter (for live demos)

- **Speech latency**: typically < 200ms
- **Action cadence**: ~1â€“2s/step in Browserâ€‘Use live sessions
- **Result time**: < 10s for common multiâ€‘step flows

## ðŸ¤ Contributing and feedback

This project was built for #nicehack69. We want your toughest sites, your worst UX, and your bug reports. Open an issue, share a URL, or propose a demo challenge â€” the agent should handle it.

Areas to contribute:
- Voice command patterns and action prompting
- Robustness across tricky UIs (iframes, shadow DOM, virtualized lists)
- Artifact exporters (GitHub PR/Issue helpers, report generators, clip makers)

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- **Browserâ€‘Use Team** â€” the core engine that turns intent into action
- **Google Gemini** â€” lowâ€‘latency speech and control
- **#nicehack69 Community** â€” for the challenge and the inspiration

---

## ðŸ Submission

- X demo post: [link coming at submission]
- GitHub issue in the Browserâ€‘Use repo: [link coming at submission]
- Public live demo URL: [coming soon]

---

*Built with â¤ï¸ for #nicehack69 â€” celebrating 69,000 GitHub stars*
